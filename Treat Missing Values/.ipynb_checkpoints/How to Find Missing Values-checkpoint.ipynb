{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5fd0714",
   "metadata": {},
   "source": [
    "# How to Find Missing Values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf725de3",
   "metadata": {},
   "source": [
    "For starters, we need to test if assigning the frequency lead to additional time periods for which data is Not Available.\n",
    "\n",
    "Again, there’s a dedicated method: is_na() which we can call on the entire data frame. We will see either “True” or “False” for every entry in the set, depending on whether there is missing data for that period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6848f9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>spx</th>\n",
       "      <th>dax</th>\n",
       "      <th>ftse</th>\n",
       "      <th>nikkei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6264</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6268</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6269 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date    spx    dax   ftse  nikkei\n",
       "0     False  False  False  False   False\n",
       "1     False  False  False  False   False\n",
       "2     False  False  False  False   False\n",
       "3     False  False  False  False   False\n",
       "4     False  False  False  False   False\n",
       "...     ...    ...    ...    ...     ...\n",
       "6264  False  False  False  False   False\n",
       "6265  False  False  False  False   False\n",
       "6266  False  False  False  False   False\n",
       "6267  False  False  False  False   False\n",
       "6268  False  False  False  False   False\n",
       "\n",
       "[6269 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lIBRARIES FOR NOTEBOOK\n",
    "import pandas as pd\n",
    "import os\n",
    "# Read & Import CSV file as dataframe\n",
    "df = pd.read_csv('Index2018.csv')\n",
    "\n",
    "# Detect missing values. Return a boolean same-sized object indicating if the values are NA. \n",
    "# NA values, such as None or numpy.NaN, gets mapped to True values.\n",
    "#df.isna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5d074d",
   "metadata": {},
   "source": [
    "To clarify, “True” indicates there are missing values and “False” suggests there aren’t.\n",
    "\n",
    "The bigger the dataset, the more difficult it becomes to spot missing entries. In binary “True” is equivalent to 1 and “False” is equivalent to 0. Therefore, we can add up the values in each column to determine the number of missing observations. For convenience, we can call the “sum()” method along with “is_na()”, like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af144c1e",
   "metadata": {},
   "source": [
    "For each attribute, this will determine the number of instances without available information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4641cd8",
   "metadata": {},
   "source": [
    "After running the cell, we see there are exactly 8 missing values for each of the market indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fe831e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date      0\n",
       "spx       0\n",
       "dax       0\n",
       "ftse      0\n",
       "nikkei    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a279",
   "metadata": {},
   "source": [
    "Recall that we had no missing values when we first examined the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a6c96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date      0\n",
       "spx       0\n",
       "dax       0\n",
       "ftse      0\n",
       "nikkei    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94caa172",
   "metadata": {},
   "source": [
    "Therefore, setting the frequency to “business days” must have generated 8 dates, for which we have no data available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb01ae",
   "metadata": {},
   "source": [
    "# How to treat missing values in a time series?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a91df17",
   "metadata": {},
   "source": [
    "Sometimes, your time series will have missing dates/times. That means, the data was not captured or was not available for those periods. It could so happen the measurement was zero on those days, in which case, case you may fill up those periods with zero.\n",
    "\n",
    "Secondly, when it comes to time series, you should typically NOT replace missing values with the mean of the series, especially if the series is not stationary. What you could do instead for a quick and dirty workaround is to forward-fill the previous value.\n",
    "\n",
    "However, depending on the nature of the series, you want to try out multiple approaches before concluding. Some effective alternatives to imputation are:\n",
    "\n",
    "- Backward Fill\n",
    "- Linear Interpolation\n",
    "- Quadratic interpolation\n",
    "- Mean of nearest neighbors\n",
    "- Mean of seasonal couterparts\n",
    "\n",
    "\n",
    "\n",
    "To measure the imputation performance, I manually introduce missing values to the time series, impute it with above approaches and then measure the mean squared error of the imputed against the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b870789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Generate dataset\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "df_orig = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'], index_col='date').head(100)\n",
    "df = pd.read_csv('https://github.com/selva86/datasets/blob/09765e913e5008b7c90c8ab49be48fce9b2d69c1/a10_missings.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "fig, axes = plt.subplots(7, 1, sharex=True, figsize=(10, 12))\n",
    "plt.rcParams.update({'xtick.bottom' : False})\n",
    "\n",
    "## 1. Actual -------------------------------\n",
    "df_orig.plot(title='Actual', ax=axes[0], label='Actual', color='red', style=\".-\")\n",
    "df.plot(title='Actual', ax=axes[0], label='Actual', color='green', style=\".-\")\n",
    "axes[0].legend([\"Missing Data\", \"Available Data\"])\n",
    "\n",
    "## 2. Forward Fill --------------------------\n",
    "df_ffill = df.ffill()\n",
    "error = np.round(mean_squared_error(df_orig['value'], df_ffill['value']), 2)\n",
    "df_ffill['value'].plot(title='Forward Fill (MSE: ' + str(error) +\")\", ax=axes[1], label='Forward Fill', style=\".-\")\n",
    "\n",
    "## 3. Backward Fill -------------------------\n",
    "df_bfill = df.bfill()\n",
    "error = np.round(mean_squared_error(df_orig['value'], df_bfill['value']), 2)\n",
    "df_bfill['value'].plot(title=\"Backward Fill (MSE: \" + str(error) +\")\", ax=axes[2], label='Back Fill', color='firebrick', style=\".-\")\n",
    "\n",
    "## 4. Linear Interpolation ------------------\n",
    "df['rownum'] = np.arange(df.shape[0])\n",
    "df_nona = df.dropna(subset = ['value'])\n",
    "f = interp1d(df_nona['rownum'], df_nona['value'])\n",
    "df['linear_fill'] = f(df['rownum'])\n",
    "error = np.round(mean_squared_error(df_orig['value'], df['linear_fill']), 2)\n",
    "df['linear_fill'].plot(title=\"Linear Fill (MSE: \" + str(error) +\")\", ax=axes[3], label='Cubic Fill', color='brown', style=\".-\")\n",
    "\n",
    "## 5. Cubic Interpolation --------------------\n",
    "f2 = interp1d(df_nona['rownum'], df_nona['value'], kind='cubic')\n",
    "df['cubic_fill'] = f2(df['rownum'])\n",
    "error = np.round(mean_squared_error(df_orig['value'], df['cubic_fill']), 2)\n",
    "df['cubic_fill'].plot(title=\"Cubic Fill (MSE: \" + str(error) +\")\", ax=axes[4], label='Cubic Fill', color='red', style=\".-\")\n",
    "\n",
    "# Interpolation References:\n",
    "# https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html\n",
    "# https://docs.scipy.org/doc/scipy/reference/interpolate.html\n",
    "\n",
    "## 6. Mean of 'n' Nearest Past Neighbors ------\n",
    "def knn_mean(ts, n):\n",
    "    out = np.copy(ts)\n",
    "    for i, val in enumerate(ts):\n",
    "        if np.isnan(val):\n",
    "            n_by_2 = np.ceil(n/2)\n",
    "            lower = np.max([0, int(i-n_by_2)])\n",
    "            upper = np.min([len(ts)+1, int(i+n_by_2)])\n",
    "            ts_near = np.concatenate([ts[lower:i], ts[i:upper]])\n",
    "            out[i] = np.nanmean(ts_near)\n",
    "    return out\n",
    "\n",
    "df['knn_mean'] = knn_mean(df.value.values, 8)\n",
    "error = np.round(mean_squared_error(df_orig['value'], df['knn_mean']), 2)\n",
    "df['knn_mean'].plot(title=\"KNN Mean (MSE: \" + str(error) +\")\", ax=axes[5], label='KNN Mean', color='tomato', alpha=0.5, style=\".-\")\n",
    "\n",
    "## 7. Seasonal Mean ----------------------------\n",
    "def seasonal_mean(ts, n, lr=0.7):\n",
    "    \"\"\"\n",
    "    Compute the mean of corresponding seasonal periods\n",
    "    ts: 1D array-like of the time series\n",
    "    n: Seasonal window length of the time series\n",
    "    \"\"\"\n",
    "    out = np.copy(ts)\n",
    "    for i, val in enumerate(ts):\n",
    "        if np.isnan(val):\n",
    "            ts_seas = ts[i-1::-n]  # previous seasons only\n",
    "            if np.isnan(np.nanmean(ts_seas)):\n",
    "                ts_seas = np.concatenate([ts[i-1::-n], ts[i::n]])  # previous and forward\n",
    "            out[i] = np.nanmean(ts_seas) * lr\n",
    "    return out\n",
    "\n",
    "df['seasonal_mean'] = seasonal_mean(df.value, n=12, lr=1.25)\n",
    "error = np.round(mean_squared_error(df_orig['value'], df['seasonal_mean']), 2)\n",
    "df['seasonal_mean'].plot(title=\"Seasonal Mean (MSE: \" + str(error) +\")\", ax=axes[6], label='Seasonal Mean', color='blue', alpha=0.5, style=\".-\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
